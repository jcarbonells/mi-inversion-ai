# -*- coding: utf-8 -*-
"""orchestrator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JlxaXEvWfNO86KrZzD5xttIZcsB5Cwn2
"""

# orchestrator.py
import os
import json
import pandas as pd
import subprocess
import sys
from datetime import datetime

# --- ConfiguraciÃ³n ---
BASE = "/content/drive/MyDrive/investment_ai"
NOTEBOOKS_DIR = f"{BASE}/notebooks"
REPORTS_DIR = f"{BASE}/reports"
DATA_DIR = f"{BASE}/data"

# Asegurar que las carpetas existan
os.makedirs(REPORTS_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)

def run_full_orchestrator(verbose=True):
    """
    Ejecuta la cadena completa de agentes con calibraciÃ³n dinÃ¡mica.

    Args:
        verbose (bool): Si True, imprime progreso detallado.

    Returns:
        tuple: (fx_signals, kpis, actions, log_message)
    """
    if verbose:
        print("ğŸ”„ Iniciando orquestador con calibraciÃ³n dinÃ¡mica...")

    # 1. Leer rendimiento histÃ³rico para calibrar pesos
    PERF_PATH = f"{REPORTS_DIR}/performance_summary.json"
    agent_weights = {"fx_agent": 1.0, "quant_signals": 1.0}

    if os.path.exists(PERF_PATH):
        try:
            with open(PERF_PATH) as f:
                perf = json.load(f)
            if "fx_agent" in perf:
                precision = perf["fx_agent"]["precision_total"]
                agent_weights["fx_agent"] = min(1.5, max(0.5, precision / 0.7))
            if verbose:
                print(f"ğŸ“Š Pesos calibrados: {agent_weights}")
        except Exception as e:
            print(f"âš ï¸ Error al leer rendimiento: {e}. Usando pesos por defecto.")
    else:
        if verbose:
            print("â„¹ï¸ No se encontrÃ³ performance_summary.json. Usando pesos por defecto.")

    # 2. Pasar pesos como variables de entorno
    os.environ["FX_AGENT_WEIGHT"] = str(agent_weights["fx_agent"])
    os.environ["QUANT_AGENT_WEIGHT"] = str(agent_weights["quant_signals"])

    # 3. Lista de notebooks a ejecutar (Â¡NO incluir el orquestador!)
    notebooks = [
        "00_liquidity_agent.ipynb",
        "01_data_prep.ipynb",
        "02_portfolio_exposure.ipynb",
        "06_portfolio_reconstructor.ipynb",
        "07_asset_metrics.ipynb",
        "11_market_analyst.ipynb",
        "12_sectorial_strength.ipynb",
        "03_fx_agent.ipynb",          # â† usarÃ¡ FX_AGENT_WEIGHT
        "04_quant_signals.ipynb",     # â† usarÃ¡ QUANT_AGENT_WEIGHT
        "05_risk_manager.ipynb",
        "07_reporter_advanced.ipynb"
        # âŒ NO incluir "09_orchestrator.ipynb" aquÃ­
    ]

    # 4. Ejecutar notebooks con manejo de errores detallado
    for nb in notebooks:
        if verbose:
            print(f"\nâ–¶ï¸ Ejecutando {nb}...")

        cmd = [
            sys.executable, "-m", "nbconvert",
            "--to", "notebook",
            "--execute",
            f"{NOTEBOOKS_DIR}/{nb}",
            "--output", f"{NOTEBOOKS_DIR}/{nb}",
            "--log-level=ERROR"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            error_msg = f"""
âŒ ERROR al ejecutar {nb}:
STDOUT: {result.stdout[-500:]}
STDERR: {result.stderr[-1000:]}
            """
            if verbose:
                print(error_msg)
            raise RuntimeError(f"Fallo en {nb}. Ver detalles arriba.")
        else:
            if verbose:
                print(f"âœ… {nb} completado.")

    # 5. Cargar resultados
    fx_path = f"{REPORTS_DIR}/fx_hedge_signal.csv"
    fx_signals = pd.read_csv(fx_path) if os.path.exists(fx_path) else pd.DataFrame()

    if verbose:
        print(f"\nğŸ“ˆ SeÃ±ales FX cargadas: {len(fx_signals)} filas")

    risk_path = f"{REPORTS_DIR}/risk_summary.json"
    kpis = {}
    if os.path.exists(risk_path):
        try:
            with open(risk_path) as f:
                kpis = json.load(f)
        except Exception as e:
            print(f"âš ï¸ Error al cargar KPIs: {e}")

    # 6. Generar acciones
    actions = []
    if not fx_signals.empty:
        for _, row in fx_signals.iterrows():
            if row["cobertura_recomendada"] == "SÃ­":
                actions.append({
                    "tipo": "cobertura_fx",
                    "divisa": row["divisa"],
                    "porcentaje": row["%_cobertura"],
                    "importe_eur": row["exposicion_eur"]
                })

    # 7. Guardar log de ejecuciÃ³n
    try:
        execution_log = {
            "fecha": datetime.now().isoformat(),
            "agent_weights": agent_weights,
            "performance_snapshot": json.load(open(PERF_PATH)) if os.path.exists(PERF_PATH) else None
        }
        with open(f"{REPORTS_DIR}/execution_log.json", "w") as f:
            json.dump(execution_log, f, indent=2)
    except Exception as e:
        print(f"âš ï¸ Error al guardar execution_log.json: {e}")

    log_msg = f"[{datetime.now().isoformat()}] Orquestador completado. Pesos: {agent_weights}"
    if verbose:
        print(f"\nâœ… {log_msg}")

    return fx_signals, kpis, actions, log_msg


# === NO EJECUTES NADA AQUÃ ===
# Este archivo SOLO define la funciÃ³n.
# Para ejecutarlo, usa un script separado o una celda en Colab:
#
# from orchestrator import run_full_orchestrator
# signals_df, kpis, actions, log = run_full_orchestrator()

# orchestrator.py
import os
import pandas as pd
import numpy as np
import json
import subprocess
import sys
from datetime import datetime, timedelta
import yfinance as yf
import glob

# --- FUNCIÃ“N PARA REGISTRAR SEÃ‘ALES (PARA PERFORMANCE AGENT) ---
def log_signal(
    agente: str,
    tipo_senal: str,
    recomendacion: str,
    contexto: dict = None,
    horizonte_eval: str = "5d",
    metadata: dict = None
):
    """
    Registra una seÃ±al emitida por un agente en signals_emitted.csv.
    """
    SIGNALS_LOG_PATH = f"{BASE}/data/signals_emitted.csv"
    os.makedirs(os.path.dirname(SIGNALS_LOG_PATH), exist_ok=True)

    new_row = {
        "fecha_emision": datetime.today().strftime("%Y-%m-%d"),
        "agente": agente,
        "tipo_senal": tipo_senal,
        "recomendacion": recomendacion,
        "contexto_liquidez": contexto.get("liquidez_regime", "N/A") if contexto else "N/A",
        "contexto_mercado": contexto.get("market_regime", "N/A") if contexto else "N/A",
        "horizonte_eval": horizonte_eval,
        "seÃ±al_id": f"{agente}_{datetime.today().strftime('%Y%m%d')}_{hash(recomendacion) % 1000:03d}"
    }

    import json as json_lib
    if metadata:
        new_row["metadata"] = json_lib.dumps(metadata, ensure_ascii=False)
    else:
        new_row["metadata"] = "{}"

    # Cargar o crear CSV
    if os.path.exists(SIGNALS_LOG_PATH):
        df = pd.read_csv(SIGNALS_LOG_PATH)
    else:
        df = pd.DataFrame(columns=[
            "fecha_emision", "agente", "tipo_senal", "recomendacion",
            "contexto_liquidez", "contexto_mercado", "horizonte_eval", "seÃ±al_id", "metadata"
        ])

    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    df.to_csv(SIGNALS_LOG_PATH, index=False, encoding="utf-8")
    print(f"âœ… SeÃ±al registrada para evaluaciÃ³n: {recomendacion[:60]}...")

# --- ConfiguraciÃ³n ---
BASE = "/content/drive/MyDrive/investment_ai"
NOTEBOOKS_DIR = f"{BASE}/notebooks"
REPORTS_DIR = f"{BASE}/reports"
DATA_DIR = f"{BASE}/data"

# --- Contratos de salida por agente ---
CONTRATOS = {
    "00_liquidity_agent.ipynb": [
        "reports/liquidity_regime_latest.json",
        "reports/liquidity_dashboard_latest.md",
        "reports/liquidity_dashboard_latest.html"
    ],
    "01_data_prep.ipynb": ["data/raw/my_portfolio_prices.parquet"],
    "02_portfolio_exposure.ipynb": ["reports/portfolio_enriched_final.csv"],
    "06_portfolio_reconstructor.ipynb": ["reports/portfolio_daily_value.csv"],
    "07_asset_metrics.ipynb": ["reports/asset_metrics.csv"],
    "11_market_analyst.ipynb": ["reports/market_regime_latest.json"],
    "12_sectorial_strength.ipynb": ["reports/sector_strength_latest.json"],
    "03_fx_agent.ipynb": ["reports/fx_hedge_latest.json"],
    "04_quant_signals.ipynb": ["reports/quant_signals_latest.json"],
    "05_risk_manager.ipynb": ["reports/risk_dashboard_latest.json"],
    "07_reporter_advanced.ipynb": ["reports/report_final_*.md"]  # PatrÃ³n
}

# --- Dependencias por agente ---
DEPENDENCIAS = {
    "03_fx_agent.ipynb": ["market_regime_latest.json", "portfolio_daily_value.csv"],
    "04_quant_signals.ipynb": ["market_regime_latest.json", "sector_strength_latest.json", "portfolio_enriched_final.csv"],
    "05_risk_manager.ipynb": ["portfolio_daily_value.csv", "portfolio_enriched_final.csv"]
}

def verificar_dependencias(notebook_name):
    """Verifica que los archivos requeridos existan antes de ejecutar el notebook."""
    if notebook_name not in DEPENDENCIAS:
        return True
    for archivo in DEPENDENCIAS[notebook_name]:
        ruta = os.path.join(REPORTS_DIR, archivo)
        if not os.path.exists(ruta):
            print(f"  âš ï¸ Dependencia faltante: {archivo} (requerido por {notebook_name})")
            return False
    return True

def validar_salidas(notebook_name):
    """Valida que el notebook generÃ³ sus archivos de salida esperados."""
    if notebook_name not in CONTRATOS:
        return True

    for archivo in CONTRATOS[notebook_name]:
        if "*" in archivo:  # PatrÃ³n como report_final_*.md
            pattern = os.path.join(BASE, archivo)
            if not glob.glob(pattern):
                print(f"  âš ï¸ Archivo de salida faltante: {pattern}")
                return False
        else:
            ruta = os.path.join(BASE, archivo)
            if not os.path.exists(ruta):
                print(f"  âš ï¸ Archivo de salida faltante: {ruta}")
                return False
    return True

def run_full_orchestrator(verbose=True):
    """
    Ejecuta la cadena completa de agentes con calibraciÃ³n dinÃ¡mica y validaciÃ³n.
    """
    if verbose:
        print("ğŸ”„ Iniciando orquestador con calibraciÃ³n dinÃ¡mica y validaciÃ³n...")

    # 1. Leer rendimiento histÃ³rico para calibrar pesos
    PERF_PATH = f"{REPORTS_DIR}/performance_summary.json"
    agent_weights = {"fx_agent": 1.0, "quant_signals": 1.0}

    if os.path.exists(PERF_PATH):
        try:
            with open(PERF_PATH) as f:
                perf = json.load(f)
            if "fx_agent" in perf:
                precision = perf["fx_agent"]["precision_total"]
                agent_weights["fx_agent"] = min(1.5, max(0.5, precision / 0.7))
            if "quant_signals" in perf:
                precision = perf["quant_signals"]["precision_total"]
                agent_weights["quant_signals"] = min(1.5, max(0.5, precision / 0.7))
            if verbose:
                print(f"ğŸ“Š Pesos calibrados: {agent_weights}")
        except Exception as e:
            print(f"âš ï¸ Error al leer rendimiento: {e}. Usando pesos por defecto.")
    else:
        if verbose:
            print("â„¹ï¸ No se encontrÃ³ performance_summary.json. Usando pesos por defecto.")

    # 2. Pasar pesos como variables de entorno
    os.environ["FX_AGENT_WEIGHT"] = str(agent_weights["fx_agent"])
    os.environ["QUANT_AGENT_WEIGHT"] = str(agent_weights["quant_signals"])

    # 3. Lista de notebooks a ejecutar (Â¡NO incluir el orquestador!)
    NOTEBOOKS = [
        "00_liquidity_agent.ipynb",      # 1. Liquidez global (independiente)
        "11_market_analyst.ipynb",       # 2. RÃ©gimen de mercado (independiente)
        "12_sectorial_strength.ipynb",   # 3. Fuerza sectorial (independiente)
        "01_data_prep.ipynb",            # 4. Precios de cartera (independiente)
        "02_portfolio_exposure.ipynb",   # 5. Cartera enriquecida (usa 01)
        "06_portfolio_reconstructor.ipynb", # 6. Valor diario (usa 01)
        "07_asset_metrics.ipynb",        # 7. MÃ©tricas por activo (usa 01 + 02)
        "03_fx_agent.ipynb",             # 8. Cobertura FX (usa 00 + 02 + 06)
        "04_quant_signals.ipynb",        # 9. SeÃ±ales cuantitativas (usa 02 + 11 + 12)
        "05_risk_manager.ipynb",         # 10. Riesgo (usa 06)
        "07_reporter_advanced.ipynb"     # 11. Reporte final (usa todos)
    ]

    # 4. Ejecutar notebooks con manejo de errores detallado
    log = []
    for nb in NOTEBOOKS:
        if verbose:
            print(f"\nâ–¶ï¸ Ejecutando {nb}...")

        if not verificar_dependencias(nb):
            print(f"  âŒ {nb} interrumpido por dependencias faltantes.")
            log.append(f"{nb}: FALLÃ“ (dependencias)")
            continue

        cmd = [
            sys.executable, "-m", "nbconvert",
            "--to", "notebook",
            "--execute",
            f"{NOTEBOOKS_DIR}/{nb}",
            "--output", f"{NOTEBOOKS_DIR}/{nb}",
            "--log-level=ERROR"
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)

        if result.returncode != 0:
            error_msg = f"""
âŒ ERROR al ejecutar {nb}:
STDOUT: {result.stdout[-500:]}
STDERR: {result.stderr[-1000:]}
            """
            if verbose:
                print(error_msg)
            log.append(f"{nb}: FALLÃ“")
        else:
            if not validar_salidas(nb):
                print(f"    âŒ {nb} no generÃ³ los archivos esperados.")
                log.append(f"{nb}: FALLÃ“ (archivos)")
            else:
                if verbose:
                    print(f"âœ… {nb} completado y validado.")
                log.append(f"{nb}: OK")

    # 5. Guardar log de ejecuciÃ³n
    log_path = f"{REPORTS_DIR}/orchestrator_log_{datetime.now().strftime('%Y%m%d')}.txt"
    with open(log_path, "w") as f:
        f.write(f"Cadena ejecutada: {datetime.now()}\n")
        f.write("\n".join(log))

    # 6. Cargar resultados finales
    signals_df, kpis, actions, log_msg = load_final_results()

    # 7. Registrar ejecuciÃ³n para evaluaciÃ³n
    try:
        with open(f"{REPORTS_DIR}/market_regime_latest.json") as f:
            market_regime = json.load(f)["regimen"]
    except:
        market_regime = "Neutral"

    try:
        with open(f"{REPORTS_DIR}/liquidity_regime_latest.json") as f:
            liquidity_regime = json.load(f)["regimen"]
    except:
        liquidity_regime = "Neutral"

    log_signal(
        agente="orchestrator",
        tipo_senal="ejecucion_completa",
        recomendacion=f"EjecuciÃ³n completada - RÃ©gimen: {market_regime}, Liquidez: {liquidity_regime}",
        contexto={
            "liquidez_regime": liquidity_regime,
            "market_regime": market_regime
        },
        horizonte_eval="5d",
        metadata={
            "fecha_ejecucion": datetime.now().isoformat(),
            "agent_weights": agent_weights,
            "resultados": {
                "total_notebooks": len(log),
                "exitosos": sum("OK" in entry for entry in log),
                "fallidos": sum("FALLÃ“" in entry for entry in log)
            }
        }
    )

    if verbose:
        print(f"\nâœ… Orquestador completado. Log guardado en: {log_path}")
        print(f"ğŸ“Š Resultados: {len(log)} notebooks, {sum('OK' in entry for entry in log)} exitosos")

    return signals_df, kpis, actions, log_msg, log

def load_final_results():
    """Carga los resultados finales generados por el orquestador."""
    # Cargar cartera
    pf_path = f"{REPORTS_DIR}/portfolio_enriched_final.csv"
    pf = pd.read_csv(pf_path) if os.path.exists(pf_path) else pd.DataFrame()

    # Cargar riesgo
    risk_path = f"{REPORTS_DIR}/risk_dashboard.csv"
    risk = pd.read_csv(risk_path) if os.path.exists(risk_path) else pd.DataFrame()

    # Cargar mÃ©tricas
    metrics_path = f"{REPORTS_DIR}/asset_metrics.csv"
    metrics = pd.read_csv(metrics_path) if os.path.exists(metrics_path) else pd.DataFrame()

    # Extraer KPIs
    total = pf["importe_actual_eur"].sum() if not pf.empty else 0

    drawdown = "N/A"
    alpha = "N/A"
    retorno_cartera = "N/A"

    if not risk.empty and 'mÃ©trica' in risk.columns:
        def get_metric_value(metric_name):
            row = risk[risk['mÃ©trica'] == metric_name]
            return row['valor'].values[0] if not row.empty else "N/A"
        drawdown = get_metric_value('Drawdown actual')
        alpha = get_metric_value('Alpha vs S&P 500')
        retorno_cartera = get_metric_value('Retorno anualizado cartera')

    kpis = {
        "total_eur": total,
        "drawdown": drawdown,
        "alpha": alpha,
        "retorno_cartera": retorno_cartera
    }

    # Acciones (simuladas)
    actions = []
    signals_df = pd.DataFrame()

    log_msg = f"[{datetime.now().isoformat()}] Orquestador completado exitosamente"
    return signals_df, kpis, actions, log_msg

def generate_ai_dashboard_summary():
    """
    Genera un anÃ¡lisis exhaustivo de la cartera usando GenAI,
    con semÃ¡foro, recomendaciÃ³n y justificaciÃ³n por indicador.
    """
    print("ğŸ§  Generando anÃ¡lisis exhaustivo con GenAI...")

    try:
        import google.generativeai as genai
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCjID5QZSe0xDvGaq7mTHcHOctWBaxaAn8")
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-2.0-flash')
    except ImportError:
        print("âš ï¸ google-generativeai no instalado. Instalando...")
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "google-generativeai"])
        import google.generativeai as genai
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCjID5QZSe0xDvGaq7mTHcHOctWBaxaAn8")
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-2.0-flash')

    # Cargar datos con manejo robusto
    pf_path = f"{REPORTS_DIR}/portfolio_enriched_final.csv"
    pf = pd.read_csv(pf_path) if os.path.exists(pf_path) else pd.DataFrame()

    risk_path = f"{REPORTS_DIR}/risk_dashboard.csv"
    risk = pd.read_csv(risk_path) if os.path.exists(risk_path) else pd.DataFrame()

    quant_path = f"{REPORTS_DIR}/quant_signals.csv"
    quant = pd.read_csv(quant_path) if os.path.exists(quant_path) else pd.DataFrame()

    fx_path = f"{REPORTS_DIR}/fx_hedge_signal.csv"
    fx = pd.read_csv(fx_path) if os.path.exists(fx_path) else pd.DataFrame()

    metrics_path = f"{REPORTS_DIR}/asset_metrics.csv"
    metrics = pd.read_csv(metrics_path) if os.path.exists(metrics_path) else pd.DataFrame()

    sectors_path = f"{REPORTS_DIR}/sector_strength_latest.json"
    sectors = {}
    if os.path.exists(sectors_path):
        with open(sectors_path) as f:
            sectors = json.load(f)

    # Extraer mÃ©tricas clave
    total = pf["importe_actual_eur"].sum() if not pf.empty else 0
    drawdown = "N/A"
    alpha = "N/A"
    retorno_cartera = "N/A"
    sp500_retorno = "N/A"

    if not risk.empty and 'mÃ©trica' in risk.columns:
        def get_metric_value(metric_name):
            row = risk[risk['mÃ©trica'] == metric_name]
            return row['valor'].values[0] if not row.empty else "N/A"
        drawdown = get_metric_value('Drawdown actual')
        alpha = get_metric_value('Alpha vs S&P 500')
        retorno_cartera = get_metric_value('Retorno anualizado cartera')
        sp500_retorno = get_metric_value('Retorno anualizado S&P 500')

    # Construir prompt para GenAI
    prompt = f"""
Eres un agente de inversiÃ³n profesional con acceso a un sistema multiagente avanzado.
Tu tarea es generar un **anÃ¡lisis exhaustivo de la cartera al {datetime.today().strftime('%Y-%m-%d')}** en formato de tabla con las siguientes columnas:

- **CategorÃ­a**: riesgo, rendimiento, concentraciÃ³n, FX, sectorial, seÃ±ales, etc.
- **Indicador**: nombre del indicador clave.
- **Valor**: valor numÃ©rico o categÃ³rico.
- **SemÃ¡foro**: usa âœ… (verde), âš ï¸ (Ã¡mbar) o âŒ (rojo).
- **Â¿Vamos bien?**: "SÃ­", "No" o "Parcialmente".
- **RecomendaciÃ³n**: acciÃ³n concreta (ej. "Rebalancear", "Aumentar XLK", "Cubrir 10% USD").
- **JustificaciÃ³n**: explica por quÃ©, citando el indicador y su valor.

**Reglas estrictas**:
- Usa **solo los datos proporcionados**.
- SÃ© **conciso, preciso y accionable**.
- No inventes datos.
- El tono debe ser profesional pero claro para un inversor no tÃ©cnico.

**Datos de la cartera**:
- Valor total: {total:,.0f} â‚¬
- Drawdown actual: {drawdown}
- Retorno anualizado cartera: {retorno_cartera}
- Retorno anualizado S&P 500: {sp500_retorno}
- Alpha vs S&P 500: {alpha}

**SeÃ±ales sectoriales (Top oportunidades)**:
{'; '.join(sectors.get('top_oportunidades', [])) if sectors else 'No disponible'}

**SeÃ±ales cuantitativas (ejemplos)**:
{quant.head(5).to_string(index=False) if not quant.empty else 'No disponible'}

**SeÃ±ales FX**:
{fx.head(5).to_string(index=False) if not fx.empty else 'No disponible'}

Genera la tabla en **formato Markdown**. No aÃ±adas introducciÃ³n ni conclusiÃ³n, solo la tabla.
"""

    try:
        response = model.generate_content(prompt)
        analysis_md = response.text

        output_path = f"{REPORTS_DIR}/ai_dashboard_summary_{datetime.today().strftime('%Y%m%d')}.md"
        with open(output_path, "w", encoding="utf-8") as f:
            f.write("# ğŸ“Š AnÃ¡lisis Exhaustivo de Cartera (GenAI)\n\n")
            f.write(f"Fecha: {datetime.today().strftime('%Y-%m-%d')}\n\n")
            f.write(analysis_md)

        print(f"âœ… AnÃ¡lisis guardado en: {output_path}")
        return analysis_md

    except Exception as e:
        error_msg = f"âš ï¸ Error al generar anÃ¡lisis con GenAI: {e}"
        print(error_msg)
        return error_msg

def answer_question(user_question):
    """
    Responde preguntas del usuario usando GenAI y los datos actuales.
    """
    try:
        import google.generativeai as genai
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCjID5QZSe0xDvGaq7mTHcHOctWBaxaAn8")
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-2.0-flash')
    except ImportError:
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "google-generativeai"])
        import google.generativeai as genai
        GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCjID5QZSe0xDvGaq7mTHcHOctWBaxaAn8")
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('models/gemini-2.0-flash')

    # Cargar datos existentes con manejo de errores
    pf_path = f"{REPORTS_DIR}/portfolio_enriched_final.csv"
    pf = pd.read_csv(pf_path) if os.path.exists(pf_path) else pd.DataFrame()

    risk_path = f"{REPORTS_DIR}/risk_dashboard.csv"
    risk = pd.read_csv(risk_path) if os.path.exists(risk_path) else pd.DataFrame()

    quant_path = f"{REPORTS_DIR}/quant_signals.csv"
    quant = pd.read_csv(quant_path) if os.path.exists(quant_path) else pd.DataFrame()

    fx_path = f"{REPORTS_DIR}/fx_hedge_signal.csv"
    fx = pd.read_csv(fx_path) if os.path.exists(fx_path) else pd.DataFrame()

    metrics_path = f"{REPORTS_DIR}/asset_metrics.csv"
    metrics = pd.read_csv(metrics_path) if os.path.exists(metrics_path) else pd.DataFrame()

    # Cargar contexto MACRO
    macro_str = "No disponible"
    macro_path = f"{REPORTS_DIR}/market_regime_latest.json"
    if os.path.exists(macro_path):
        with open(macro_path) as f:
            macro = json.load(f)
        macro_str = f"{macro['regimen']} (Score: {macro['score']:.2f}, Percentil: {macro['percentil']:.0f}%)"

    # Cargar fuerza SECTORIAL
    sectors_str = "No disponible"
    sectors_path = f"{REPORTS_DIR}/sector_strength_latest.json"
    if os.path.exists(sectors_path):
        with open(sectors_path) as f:
            sectors_data = json.load(f)
        if sectors_data.get("top_oportunidades"):
            sectors_str = "; ".join(sectors_data["top_oportunidades"])

    # Extraer KPIs de riesgo
    drawdown = "N/A"
    alpha = "N/A"

    if not risk.empty and 'mÃ©trica' in risk.columns:
        def get_metric_value(metric_name):
            row = risk[risk['mÃ©trica'] == metric_name]
            return row['valor'].values[0] if not row.empty else "N/A"
        drawdown = get_metric_value('Drawdown actual')
        alpha = get_metric_value('Alpha vs S&P 500')

    total = pf["importe_actual_eur"].sum() if not pf.empty else 0
    quant_summary = "Ninguna" if quant.empty else ", ".join([f"{row['Activo']}: {row['SeÃ±al']}" for _, row in quant.iterrows()])
    fx_summary = "Ninguna" if fx.empty else ", ".join([f"{row['divisa']}: {row['cobertura_recomendada']} ({row['%_cobertura']}%)" for _, row in fx.iterrows()])
    acn_alpha = "N/A"
    if not metrics.empty and "ACN" in metrics["Activo"].values:
        acn_row = metrics[metrics["Activo"] == "ACN"].iloc[0]
        acn_alpha = f"{acn_row['Retorno total mejorado']:.1%}" if pd.notna(acn_row.get('Retorno total mejorado')) else "N/A"

    context = f"""
    Eres un asistente de inversiÃ³n personal. Responde usando SOLO estos datos:

    **Contexto Macro Actual:**
    - RÃ©gimen: {macro_str}

    **Fuerza Sectorial (Top oportunidades):**
    - {sectors_str}

    **Cartera Global:**
    - Valor total: {total:,.0f} â‚¬
    - Drawdown: {drawdown}
    - Alpha vs S&P 500: {alpha}

    **SeÃ±ales Cuantitativas:**
    - {quant_summary}

    **SeÃ±ales FX:**
    - {fx_summary}

    **Insights por Activo:**
    - Alpha de ACN (incluyendo regalos): {acn_alpha}

    Pregunta del usuario: {user_question}
    """

    response = model.generate_content(context)
    return response.text

# === INTERFAZ PRINCIPAL ===
def main():
    print("ğŸ§  Orchestrator + Agente GenAI Activo (FusiÃ³n)")
    print("Comandos:")
    print("- 'semanal': ejecuta la cadena completa de agentes")
    print("- 'pregunta [tu pregunta]': interactÃºa con GenAI")
    print("- 'analisis': genera anÃ¡lisis exhaustivo con GenAI")
    print("- 'salir': termina")

    while True:
        user_input = input("\n> ").strip()

        if user_input == "salir":
            break
        elif user_input == "semanal":
            run_full_orchestrator(verbose=True)
        elif user_input.startswith("pregunta "):
            question = user_input[9:]
            answer = answer_question(question)
            print(f"\nğŸ¤– {answer}")
        elif user_input == "analisis":
            generate_ai_dashboard_summary()
        else:
            print("â“ Comando no reconocido. Usa 'semanal', 'pregunta ...', 'analisis' o 'salir'.")

if __name__ == "__main__":
    main()